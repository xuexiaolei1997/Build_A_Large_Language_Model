{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 指令微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1719309589135](../image/从零开始构建LLM/1719309589135.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "import urllib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "from transformers import GPT2Model\n",
    "\n",
    "from scripts.GPTmodel import GPTModel\n",
    "from scripts.scripts import load_weights_into_gpt, calc_loss_loader, plot_losses, generate, text_to_token_ids, token_ids_to_text, train_model_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 指令微调介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "功能概览\n",
    "\n",
    "![1719309666974](../image/从零开始构建LLM/1719309666974.png)\n",
    "\n",
    "流程\n",
    "\n",
    "![1719309789448](../image/从零开始构建LLM/1719309789448.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 7.2 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"../data/instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"What is an antonym of 'complicated'?\",\n",
       " 'input': '',\n",
       " 'output': \"An antonym of 'complicated' is 'simple'.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data\n",
    "data[999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM的输入由多种形式，下图展示了两种形式：Alpaca和Phi-3，本文使用Alpaca形式进行训练。<br/>\n",
    "训练格式应当如下图所示：\n",
    "\n",
    "![1719373091773](../image/从零开始构建LLM/1719373091773.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Training set length: 935\n",
      ">> Validation set length: 55\n",
      ">> Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\">> Training set length:\", len(train_data))\n",
    "print(\">> Validation set length:\", len(val_data))\n",
    "print(\">> Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 数据封装\n",
    "\n",
    "![1719380932620](../image/从零开始构建LLM/1719380932620.png)\n",
    "\n",
    "![1719381496083](../image/从零开始构建LLM/1719381496083.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        for entry in data:\n",
    "            instruction_plus_input = self.format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "    \n",
    "    def format_input(self, entry):\n",
    "        instruction_text = (\n",
    "            f\"Below is an instruction that describes a task. \"\n",
    "            f\"Write a response that appropriately completes the request.\"\n",
    "            f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "        )\n",
    "\n",
    "        input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "        return instruction_text + input_text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_texts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "    batch_max_length = max(len(entry)+1 for entry in batch)\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for entry in batch:\n",
    "        new_entry = entry.copy()\n",
    "        new_entry += [pad_token_id]\n",
    "\n",
    "        padded = new_entry + [pad_token_id] * (batch_max_length - len(new_entry))\n",
    "\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        \n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        \n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 创建dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 1024)\n",
       "  (wpe): Embedding(1024, 1024)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-23): 24 x GPT2Block(\n",
       "      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_model = GPT2Model.from_pretrained(\"../models/gpt2-medium\")\n",
    "gpt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\Build_A_Large_Language_Model\\code\\scripts\\scripts.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  left.copy_(torch.tensor(right))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(model, gpt_model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 微调指令大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.8324549198150635\n",
      "Validation loss: 3.7619208812713625\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 1, step  00000: train loss 2.5239, val loss 2.5420\n",
      ">> Epoch 1, step  00005: train loss 1.0049, val loss 1.0680\n",
      ">> Epoch 1, step  00010: train loss 0.7746, val loss 0.9473\n",
      ">> Epoch 1, step  00015: train loss 0.8621, val loss 0.9093\n",
      ">> Epoch 1, step  00020: train loss 0.8994, val loss 0.8823\n",
      ">> Epoch 1, step  00025: train loss 0.7246, val loss 0.8580\n",
      ">> Epoch 1, step  00030: train loss 0.7472, val loss 0.8450\n",
      ">> Epoch 1, step  00035: train loss 0.6855, val loss 0.8197\n",
      ">> Epoch 1, step  00040: train loss 0.7196, val loss 0.7955\n",
      ">> Epoch 1, step  00045: train loss 0.6104, val loss 0.7674\n",
      ">> Epoch 1, step  00050: train loss 0.5730, val loss 0.7627\n",
      ">> Epoch 1, step  00055: train loss 0.5825, val loss 0.7548\n",
      ">> Epoch 1, step  00060: train loss 0.5951, val loss 0.7522\n",
      ">> Epoch 1, step  00065: train loss 0.5697, val loss 0.7430\n",
      ">> Epoch 1, step  00070: train loss 0.5476, val loss 0.7388\n",
      ">> Epoch 1, step  00075: train loss 0.4907, val loss 0.7310\n",
      ">> Epoch 1, step  00080: train loss 0.5559, val loss 0.7156\n",
      ">> Epoch 1, step  00085: train loss 0.5360, val loss 0.7037\n",
      ">> Epoch 1, step  00090: train loss 0.5864, val loss 0.6976\n",
      ">> Epoch 1, step  00095: train loss 0.5355, val loss 0.6910\n",
      ">> Epoch 1, step  00100: train loss 0.4997, val loss 0.6919\n",
      ">> Epoch 1, step  00105: train loss 0.4480, val loss 0.6770\n",
      ">> Epoch 1, step  00110: train loss 0.5537, val loss 0.6695\n",
      ">> Epoch 1, step  00115: train loss 0.4813, val loss 0.6624\n",
      ">> Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.' --> Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The active sentence is 'The chef cooks the meal every day.'<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the opposite of\n",
      ">> Epoch 2, step  00120: train loss 0.4294, val loss 0.6584\n",
      ">> Epoch 2, step  00125: train loss 0.4410, val loss 0.6719\n",
      ">> Epoch 2, step  00130: train loss 0.4296, val loss 0.6730\n",
      ">> Epoch 2, step  00135: train loss 0.4322, val loss 0.6678\n",
      ">> Epoch 2, step  00140: train loss 0.4631, val loss 0.6581\n",
      ">> Epoch 2, step  00145: train loss 0.4389, val loss 0.6531\n",
      ">> Epoch 2, step  00150: train loss 0.4393, val loss 0.6492\n",
      ">> Epoch 2, step  00155: train loss 0.3895, val loss 0.6431\n",
      ">> Epoch 2, step  00160: train loss 0.3699, val loss 0.6511\n",
      ">> Epoch 2, step  00165: train loss 0.3850, val loss 0.6556\n",
      ">> Epoch 2, step  00170: train loss 0.3966, val loss 0.6475\n",
      ">> Epoch 2, step  00175: train loss 0.4009, val loss 0.6367\n",
      ">> Epoch 2, step  00180: train loss 0.4100, val loss 0.6402\n",
      ">> Epoch 2, step  00185: train loss 0.3200, val loss 0.6465\n",
      ">> Epoch 2, step  00190: train loss 0.3502, val loss 0.6568\n",
      ">> Epoch 2, step  00195: train loss 0.3670, val loss 0.6498\n",
      ">> Epoch 2, step  00200: train loss 0.3306, val loss 0.6462\n",
      ">> Epoch 2, step  00205: train loss 0.3530, val loss 0.6524\n",
      ">> Epoch 2, step  00210: train loss 0.3067, val loss 0.6576\n",
      ">> Epoch 2, step  00215: train loss 0.3105, val loss 0.6598\n",
      ">> Epoch 2, step  00220: train loss 0.2984, val loss 0.6649\n",
      ">> Epoch 2, step  00225: train loss 0.2916, val loss 0.6666\n",
      ">> Epoch 2, step  00230: train loss 0.3291, val loss 0.6621\n",
      ">> Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.' --> Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of Spain?\n",
      "\n",
      "###\n",
      "Training completed in 139.83 minutes.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 提取并保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of Germany?\n",
      "\n",
      "\n",
      "The capital of Germany is Berlin.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of Spain?\n",
      "\n",
      "\n",
      "The capital of Spain is Madrid.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of the United Kingdom?\n",
      "\n",
      "\n",
      "The capital of the United Kingdom is London.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of the United States?\n",
      "\n",
      "\n",
      "The capital of the United States is Washington, D.C.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the capital of the United Kingdom?\n",
      "\n",
      "\n",
      "The capital of the\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is a type of cloud.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of animal is a 'sparrow'?\n",
      "\n",
      "\n",
      "A sparrow is a type of bird.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chloride?\n",
      "\n",
      "\n",
      "The chemical formula for sodium chloride is NaCl.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chloride?\n",
      "\n",
      "\n",
      "The chemical formula for sodium chloride is NaCl.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chloride?\n",
      "\n",
      "\n",
      "The chemical formula for sodium chloride is NaCl.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chloride?\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chloride?\n",
      "\n",
      "\n",
      "The chemical formula for sodium chloride is NaCl.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chloride?\n",
      "\n",
      "\n",
      "The chemical formula for sodium chloride is NaCl.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chloride?\n",
      "\n",
      "\n",
      "The chemical formula for sodium chloride is NaCl.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical formula for sodium chloride?\n",
      "\n",
      "\n",
      "The chemical formula for sodium chloride is NaCl.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the chemical\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/custom/instruction-model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 评估微调后的 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "使用Ollama进行评估"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
