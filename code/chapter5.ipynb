{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 在未标记的数据上进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 评估生成文本模型\n",
    "\n",
    "![1718851702204](../image/从零开始构建LLM/1718851702204.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1.1 使用GPT模型生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts.GPTmodel import GPTModel\n",
    "from scripts.scripts import generate_text_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与之前的进行对比，context_length减少到256（之前为1024），这一改变减少了计算需求，使得能够在桌面版计算机(laptop desktop)上运行。\n",
    "在之后的训练中，将其更新回1024，以便于加载预训练模型。\n",
    "\n",
    "三步生成文本的过程：\n",
    "1. tokenizer将输入文本转换为一系列token IDs\n",
    "2. 模型将token IDs转换为对应的logits，logits表示每个token在字典中可能的分布状况\n",
    "3. 将logits转换为token IDs，tokenizer再进行解码，生成文本\n",
    "\n",
    "![1718853446792](../image/从零开始构建LLM/1718853446792.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    decoded = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> encoded: tensor([[6109, 3626, 6100,  345]])\n",
      ">> decoded_text: Every effort moves youvationably sixth WWE Naturally fortune score honoured Dallasextreme\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "encoded = text_to_token_ids(start_context, tokenizer)\n",
    "print(\">> encoded:\", encoded)\n",
    "\n",
    "token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=10, context_size=GPT_CONFIG_124M['context_length'])\n",
    "\n",
    "decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(\">> decoded_text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 计算文本生成的损失\n",
    "\n",
    "![1718854323771](../image/从零开始构建LLM/1718854323771.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> probas:  tensor([[[1.8572e-05, 1.2867e-05, 1.0348e-05,  ..., 1.3664e-05,\n",
      "          9.2556e-06, 2.2009e-05],\n",
      "         [2.3067e-05, 1.8083e-05, 1.2638e-05,  ..., 1.4849e-05,\n",
      "          7.1591e-06, 3.0771e-05],\n",
      "         [2.0588e-05, 1.2996e-05, 1.5177e-05,  ..., 1.8670e-05,\n",
      "          2.3397e-05, 7.5619e-06]],\n",
      "\n",
      "        [[5.0293e-05, 4.9116e-06, 2.7594e-05,  ..., 1.7464e-05,\n",
      "          2.0475e-05, 4.7268e-05],\n",
      "         [2.0319e-05, 6.0855e-06, 1.3149e-05,  ..., 3.8269e-05,\n",
      "          7.7382e-06, 4.4218e-05],\n",
      "         [1.8622e-05, 1.7539e-05, 3.4765e-05,  ..., 2.4357e-05,\n",
      "          2.1983e-05, 1.0918e-05]]])\n",
      ">> token_ids:  tensor([[[33635],\n",
      "         [28624],\n",
      "         [34407]],\n",
      "\n",
      "        [[11896],\n",
      "         [38371],\n",
      "         [  115]]])\n",
      ">> target batch:   effort moves you\n",
      ">> predicted batch:  ESEaples perk\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\">> probas: \", probas)\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\">> token_ids: \", token_ids)\n",
    "\n",
    "print(\">> target batch: \", token_ids_to_text(targets[0], tokenizer))\n",
    "print(\">> predicted batch: \", token_ids_to_text(token_ids[0].flatten(), tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于还未被训练，因此产生的为随机文本。\n",
    "训练过程是不断减小目标与预测值之间的“距离”。\n",
    "\n",
    "![1718868480909](../image/从零开始构建LLM/1718868480909.png)\n",
    "\n",
    "具体过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Text 1: tensor([5.7994e-05, 4.7971e-05, 1.5435e-05])\n",
      ">> Text 2: tensor([1.1777e-05, 1.2350e-05, 9.3149e-06])\n",
      ">> log probas:  tensor([ -9.7552,  -9.9449, -11.0788, -11.3493, -11.3018, -11.5839])\n",
      ">> avg log probas:  tensor(-10.8357)\n",
      ">> neg avg log probas:  tensor(10.8357)\n"
     ]
    }
   ],
   "source": [
    "# 2-3\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\">> Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\">> Text 2:\", target_probas_2)\n",
    "\n",
    "# 4\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(\">> log probas: \", log_probas)\n",
    "\n",
    "# 5\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\">> avg log probas: \", avg_log_probas)\n",
    "\n",
    "# 6\n",
    "neg_avg_log_probas = -avg_log_probas\n",
    "print(\">> neg avg log probas: \", neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉熵 Cross Entropy Loss， 是用来衡量两个概率分布之间的差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Logits shape: torch.Size([2, 3, 50257])\n",
      ">> Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
    "print(\">> Logits shape:\", logits.shape)\n",
    "\n",
    "# Targets have shape (batch_size, num_tokens)\n",
    "print(\">> Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在进行交叉熵之前，需要检查向量维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Flattened logits: torch.Size([6, 50257])\n",
      ">> Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\">> Flattened logits:\", logits_flat.shape)\n",
    "print(\">> Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loss:  tensor(10.8357)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\">> Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 困惑度</br>\n",
    "\n",
    "困惑度也是评价语言模型好坏的指标。它可以提供一种更可解释的方法来理解模型在预测序列中的下一个标记时的不确定性。</br>\n",
    "困惑度衡量了模型预测的概率分布与数据集中单词的实际分布的匹配程度。与损失相似，较低的困惑度表明模型的预测更接近实际分布。</br>\n",
    "困惑度的可解释性在于它表示模型在每一步中都不确定的有效词汇表大小。</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50800.4258)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 计算训练和验证损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join('..', 'data', 'the-verdict.txt')\n",
    "assert os.path.exists(filepath), f\"{filepath} is not exists.\"\n",
    "with open(filepath) as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Characters: 20479\n",
      ">> Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "text_data = raw_text\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\">> Characters:\", total_characters)\n",
    "print(\">> Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1718868663879](../image/从零开始构建LLM/1718868663879.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(len(text_data) * train_ratio)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From chapter2.ipynb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader_v1(train_data, \n",
    "                                    batch_size=2, \n",
    "                                    max_length=GPT_CONFIG_124M['context_length'], \n",
    "                                    stride=GPT_CONFIG_124M['context_length'], \n",
    "                                    drop_last=True, \n",
    "                                    shuffle=True)\n",
    "val_loader = create_dataloader_v1(val_data, \n",
    "                                  batch_size=2, \n",
    "                                  max_length=GPT_CONFIG_124M['context_length'], \n",
    "                                  stride=GPT_CONFIG_124M['context_length'], \n",
    "                                  drop_last=False, \n",
    "                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(len(data_loader), num_batches)\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Train loss: 10.990836249457466\n",
      ">> Val loss: 10.99935245513916\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "print(f\">> Train loss: {train_loss}\")\n",
    "\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(f\">> Val loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 训练一个LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1718875144870](../image/从零开始构建LLM/1718875144870.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluete_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    excoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(model, excoded, 50 , context_size)\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(f\">> {start_context} --> {decoded_text}\")\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_token_seen = [], [], []\n",
    "    token_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            token_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluete_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_token_seen.append(token_seen)\n",
    "                print(f\">> Epoch {epoch + 1}, step {global_step: 06d}: train loss {train_loss:.4f}, val loss {val_loss:.4f}\")\n",
    "    \n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_token_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Epoch 1, step  00000: train loss 9.7878, val loss 10.0392\n",
      ">> Epoch 1, step  00005: train loss 8.1311, val loss 8.4105\n",
      ">> Every effort moves you --> Every effort moves you,.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1  # Change Here\n",
    "train_losses, val_losses, track_token_seen = train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
    "                                                               num_epochs, 5, 5, \"Every effort moves you\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "save_path = os.path.join('..', 'models', 'custom', 'basic_model.pth')\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "# load model\n",
    "# model = GPTModel(GPT_CONFIG_124M)\n",
    "# model.load_state_dict(torch.load(save_path))\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    ax.plot(epochs_seen, train_losses, label=\"train\")\n",
    "    ax.plot(epochs_seen, val_losses, linestyle='-.', label=\"val\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()\n",
    "\n",
    "    ax1 = ax.twiny()\n",
    "    ax1.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax1.set_xlabel(\"Tokens Seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epoch_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epoch_tensor, track_token_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 控制随机性的解码策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "主要介绍两个函数：`temperature scaling` 和 `top-k sampling`\n",
    "\n",
    "首先需要将模型转到cpu上，因为较小的模型在推理时不需要gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Temperature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "一种添加概率选择过程到向下一代标记生成任务的技术。</br>\n",
    "在前面的章节中，`generate_text_simple` 函数使用 `torch.argmax` 取最大概率，这一行为被称为贪婪解码 greedy decode。</br>\n",
    "为了使输出更加多样化，我们使用 **`从概率分布进行采样`** 来替换掉`argmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> inverse vocab (argmax):  forward\n",
      ">> inverse vocab (probability distribution):  forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "print(\">> inverse vocab (argmax): \", inverse_vocab[next_token_id])\n",
    "\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(\">> inverse vocab (probability distribution): \", inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印出来的结果都是forward。`multinomial`是根据概率分数的比例来对下一个标记进行采样。因此在这里，forward仍然是最大的概率分数。在执行多次后我们统计一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> sampled 80 times: closer\n",
      ">> sampled 1 times: every\n",
      ">> sampled 0 times: effort\n",
      ">> sampled 579 times: forward\n",
      ">> sampled 1 times: inches\n",
      ">> sampled 0 times: moves\n",
      ">> sampled 0 times: pizza\n",
      ">> sampled 336 times: toward\n",
      ">> sampled 3 times: you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))  \n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\">> sampled {freq} times: {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，与argmax不同，大部分情况下，会选择`forward`但是也有其他的可能。</br>\n",
    "我们可以通过一个叫做`temperature scaling`的概念来控制分布和选择过程。`temperature scaling`只是一个大于0的树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temperature大于1会得到更加均匀的分布，小于1则会得到更尖锐的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, t) for t in temperatures]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, T in enumerate(temperatures):\n",
    "    ax.bar(x + i * bar_width, scaled_probas[i], width=bar_width, label=f\"T={T}\")\n",
    "\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(list(vocab.keys()), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "上一节的温度采样和温度尺度可能会生成错误的结果，为了使结果更加准确，我们采用Tok-k采样。当结合概率采样和温度尺度时，可以提高文本生成结果。\n",
    "\n",
    "在top-k抽样中，我们可以将采样的标记限制在最可能的top-k标记中，并通过屏蔽其概率分数，从选择过程中排除所有其他标记，如下图所示。\n",
    "\n",
    "![1718954311719](../image/从零开始构建LLM/1718954311719.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> top logits:  tensor([6.7500, 6.2800, 4.5100])\n",
      ">> top positions:  tensor([3, 7, 0])\n",
      ">> new logits:  tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      ">> topk probas:  tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# >> top k and position\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\">> top logits: \", top_logits)\n",
    "print(\">> top positions: \", top_pos)\n",
    "\n",
    "# >> mask logits\n",
    "new_logits = torch.where(condition=next_token_logits < top_logits[-1],\n",
    "                         input=torch.tensor(float('-inf')),\n",
    "                         other=next_token_logits)\n",
    "print(\">> new logits: \", new_logits)\n",
    "\n",
    "# >> topk probas\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(\">> topk probas: \", topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此引入温度尺度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 修改文本生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # >> context\n",
    "        idx_cond = idx if idx.size(0) <= context_size else idx[-context_size:]\n",
    "\n",
    "        # >> logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]  # last\n",
    "\n",
    "        # >> topk\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]  # min value\n",
    "            # mask logits\n",
    "            logits = torch.where(condition=logits < min_val, input=torch.tensor(float('-inf')), other=logits)\n",
    "        \n",
    "        # >> temperature\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text:  Every effort moves you I\n",
      " a of to with. the\"-- of the a to his\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(model=model, idx=text_to_token_ids(\"Every effort moves you\", tokenizer), \n",
    "                     max_new_tokens=15, \n",
    "                     context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "                     top_k=25,\n",
    "                     temperature=1.4)\n",
    "print(\">> generated text: \", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 在PyTorch中加载和保存模型权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了原始的保存模型之外，可以保存优化器等参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> model.eval()作用：**禁用dropout**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdamW使用历史数据来动态调整每个模型参数的学习速率。如果没有它，优化器就会重置，模型可能会学习次优，甚至不能正确收敛，这意味着它将失去生成连贯文本的能力。使用torch.save，我们可以保存模型和优化器的state_dict的内容如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.join(\"..\", \"models\", \"custom\", \"model_and_optimizer.pth\")\n",
    "\n",
    "# save model and optimizer\n",
    "torch.save({\n",
    "    \"model_states_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "}, model_path)\n",
    "\n",
    "# load model and optimizer\n",
    "checkpoint = torch.load(model_path)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_states_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 从OpenAI中加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt_download.py\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        # Get the total file size from headers, defaulting to 0 if not present\n",
    "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "        # Check if file exists and has the same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return\n",
    "\n",
    "        # Define the block size for reading the file\n",
    "        block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "        # Initialize the progress bar with total file size\n",
    "        progress_bar_description = os.path.basename(url)  # Extract filename from URL\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "            # Open the destination file in binary write mode\n",
    "            with open(destination, \"wb\") as file:\n",
    "                # Read the file in chunks and write to destination\n",
    "                while True:\n",
    "                    chunk = response.read(block_size)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    file.write(chunk)\n",
    "                    progress_bar.update(len(chunk))  # Update progress bar\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings, params = download_and_load_gpt2(\"124M\", \"models\")\n",
    "print(\"settings: \", settings)\n",
    "print(\"params: \", params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 上述代码出错，分析原因为torch、tensorflow的部分不兼容， 没有找到好的解决方案，因此使用其他方法来解决<br/>\n",
    "\n",
    "安装transformers包：`pip install transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方案一：使用包从huggingface上下载，可以直接使用，这一部分网上代码很多\n",
    "\n",
    "> 可能也会报错，出现网络错误，无法连接等问题（比较看脸）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline, set_seed\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方案二：手动从[huggingface的gpt2模型](https://huggingface.co/openai-community/gpt2/tree/main)中下载，其中，下载示例脚本在[download_huggingface_model.ipynb](./scripts/download_huggingface_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> config: GPT2Config {\n",
      "  \"_name_or_path\": \"../models/gpt2/config.json\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.36.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Model, GPT2Tokenizer, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"../models/gpt2/config.json\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"../models/gpt2/\")\n",
    "model = GPT2Model.from_pretrained(\"../models/gpt2/\")\n",
    "\n",
    "print(\">> config:\", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> tokenizer: GPT2Tokenizer(name_or_path='../models/gpt2/', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\">> tokenizer:\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> model: GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\">> model:\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1719213912457](../image/从零开始构建LLM/1719213912457.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453],\n",
       "        [ 0.0403, -0.0486,  0.0462,  ...,  0.0861,  0.0025,  0.0432],\n",
       "        [-0.1275,  0.0479,  0.1841,  ...,  0.0899, -0.1297, -0.0879],\n",
       "        ...,\n",
       "        [-0.0445, -0.0548,  0.0123,  ...,  0.1044,  0.0978, -0.0695],\n",
       "        [ 0.1860,  0.0167,  0.0461,  ..., -0.0963,  0.0785, -0.0225],\n",
       "        [ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model's block weight\n",
    "model.wte.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来将模型参数加载至我们自己的GPTModel中，首先选用最小的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layer): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()\n",
    "gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载函数如下，其中，转置操作应当一致，无法修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_into_gpt(gpt, model):\n",
    "\n",
    "    def assign(left, right):\n",
    "        if left.shape != right.shape:\n",
    "            raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "        with torch.no_grad():\n",
    "            left.copy_(torch.tensor(right))\n",
    "    \n",
    "    assign(gpt.tok_emb.weight, model.wte.weight)\n",
    "    assign(gpt.pos_emb.weight, model.wpe.weight)\n",
    "\n",
    "    for b in range(len(model.h)):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            model.h[b].attn.c_attn.weight, 3, axis=-1\n",
    "        )\n",
    "\n",
    "        assign(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        assign(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        assign(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            model.h[b].attn.c_attn.bias, 3, axis=-1\n",
    "        )\n",
    "\n",
    "        assign(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        assign(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "        \n",
    "        assign(gpt.trf_blocks[b].att.out_proj.weight, model.h[b].attn.c_proj.weight.T)\n",
    "        assign(gpt.trf_blocks[b].att.out_proj.bias, model.h[b].attn.c_proj.bias)\n",
    "\n",
    "        assign(gpt.trf_blocks[b].ff.layer[0].weight, model.h[b].mlp.c_fc.weight.T)\n",
    "        assign(gpt.trf_blocks[b].ff.layer[0].bias, model.h[b].mlp.c_fc.bias)\n",
    "        assign(gpt.trf_blocks[b].ff.layer[2].weight, model.h[b].mlp.c_proj.weight.T)\n",
    "        assign(gpt.trf_blocks[b].ff.layer[2].bias, model.h[b].mlp.c_proj.bias)\n",
    "\n",
    "        assign(gpt.trf_blocks[b].norm1.scale, model.h[b].ln_1.weight)\n",
    "        assign(gpt.trf_blocks[b].norm1.shift, model.h[b].ln_1.bias)\n",
    "        assign(gpt.trf_blocks[b].norm2.scale, model.h[b].ln_2.weight)\n",
    "        assign(gpt.trf_blocks[b].norm2.shift, model.h[b].ln_2.bias)\n",
    "    \n",
    "    assign(gpt.final_norm.scale, model.ln_f.weight)\n",
    "    assign(gpt.final_norm.shift, model.ln_f.bias)\n",
    "    assign(gpt.out_head.weight, model.wte.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuexiaolei\\AppData\\Local\\Temp\\ipykernel_36220\\2137781906.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  left.copy_(torch.tensor(right))\n"
     ]
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证模型生成效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'allowed_special': {'<|endoftext|>'}} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> generated text By MyGPT: \n",
      " Once upon a time of deep crisis, in particular those at their disposal in these perilous situations — as far back as the days of Napoleon himself—we will see how they came to this state of affairs, and how they came to collapse quickly. This is the state of\n"
     ]
    }
   ],
   "source": [
    "tokenids = generate(gpt, idx=text_to_token_ids(\"Once upon a time\", tokenizer).to(device),\n",
    "         max_new_tokens=50, context_size=NEW_CONFIG['context_length'],\n",
    "         top_k=50, temperature=1.5)\n",
    "print(\">> generated text By MyGPT: \\n\", token_ids_to_text(tokenids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a timeageageageageageageageageageageageageageageageageageageageageageageageageage\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "def generate_by_gpt2(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # >> context\n",
    "        idx_cond = idx if idx.size(0) <= context_size else idx[-context_size:]\n",
    "\n",
    "        # >> logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits.last_hidden_state[:, -1, :]  # last\n",
    "\n",
    "        # >> topk\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]  # min value\n",
    "            # mask logits\n",
    "            logits = torch.where(condition=logits < min_val, input=torch.tensor(float('-inf')), other=logits)\n",
    "        \n",
    "        # >> temperature\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "model.eval()\n",
    "\n",
    "generated_ids = generate_by_gpt2(model, idx=tokenizer.encode(\"Once upon a time\", return_tensors='pt'),\n",
    "         max_new_tokens=25, context_size=NEW_CONFIG['context_length'],\n",
    "         top_k=50, temperature=1.5)\n",
    "# 解码生成的文本\n",
    "generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> GPT2Model 与 GPTLMHeadModel不一样， GPT2Model主要用于获取模型的隐藏状态，而GPTLMHeadModel集成了GPT2Model并添加了语言建模的头部，使其能够进行文本生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "GPT2LMHeadModel____ = GPT2LMHeadModel.from_pretrained('../models/gpt2')\n",
    "\n",
    "text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\">> generated text: \\n\", generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
